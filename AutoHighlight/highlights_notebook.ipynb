{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c7c57c",
   "metadata": {},
   "source": [
    "# Video Highlights Generation\n",
    "\n",
    "This notebook generates video highlights from a video file using Azure AI services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa68553",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "1. Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4810bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing essential packages...\n",
      "Installing openai...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Popen.__init__() got an unexpected keyword argument 'capture_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInstalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minstall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Successfully installed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:410\u001b[39m, in \u001b[36mcheck_call\u001b[39m\u001b[34m(*popenargs, **kwargs)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_call\u001b[39m(*popenargs, **kwargs):\n\u001b[32m    401\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[32m    403\u001b[39m \u001b[33;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m \u001b[33;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     retcode = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[32m    412\u001b[39m         cmd = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:391\u001b[39m, in \u001b[36mcall\u001b[39m\u001b[34m(timeout, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(*popenargs, timeout=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[33;03m    for timeout seconds, then return the returncode attribute.\u001b[39;00m\n\u001b[32m    386\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m \u001b[33;03m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[32m    392\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    393\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m p.wait(timeout=timeout)\n",
      "\u001b[31mTypeError\u001b[39m: Popen.__init__() got an unexpected keyword argument 'capture_output'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Install only essential packages needed for the pipeline\n",
    "# Using a minimal, reliable set to avoid dependency conflicts\n",
    "essential_packages = [\n",
    "    'openai',\n",
    "    'python-dotenv',\n",
    "    'requests',\n",
    "    'jsonschema',\n",
    "    'moviepy',\n",
    "    'Pillow',\n",
    "    'azure-identity'\n",
    "]\n",
    "\n",
    "print(\"Installing essential packages...\")\n",
    "failed_packages = []\n",
    "\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package], \n",
    "                            capture_output=False, text=True)\n",
    "        print(f\"✓ Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"✗ Failed to install {package}\")\n",
    "        failed_packages.append(package)\n",
    "\n",
    "if failed_packages:\n",
    "    print(f\"\\nFailed packages: {failed_packages}\")\n",
    "    print(\"The notebook may still work if these are optional dependencies.\")\n",
    "else:\n",
    "    print(\"\\n✓ All essential packages installed successfully!\")\n",
    "\n",
    "print(\"\\nPackage installation complete!\")\n",
    "\n",
    "# Test critical imports\n",
    "print(\"\\nTesting critical imports...\")\n",
    "try:\n",
    "    import moviepy.editor\n",
    "    print(\"✓ moviepy import successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ moviepy import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    print(\"✓ openai import successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ openai import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import jsonschema\n",
    "    print(\"✓ jsonschema import successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ jsonschema import failed: {e}\")\n",
    "\n",
    "print(\"\\nReady to proceed with the notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99419176",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3290509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "# Add necessary environment variables here\n",
    "# e.g., AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464ab1c",
   "metadata": {},
   "source": [
    "## Pipeline Configuration\n",
    "\n",
    "Configure the settings for the highlight generation pipeline.\n",
    "**Important:** You must specify the `SOURCE_VIDEO_PATH` before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab14fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Video: C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\Satya Build Keynote (Density - 2.5, Time - 100s).mp4\n",
      "Output Directory: C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# --- REQUIRED: SPECIFY YOUR VIDEO PATH ---\n",
    "SOURCE_VIDEO_PATH = r\"C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\Satya Build Keynote (Density - 2.5, Time - 100s).mp4\" # e.g., \"path/to/your/video.mp4\"\n",
    "\n",
    "# --- Optional: Adjust other settings ---\n",
    "OUTPUT_DIR = os.path.dirname(os.path.abspath(SOURCE_VIDEO_PATH if SOURCE_VIDEO_PATH else __file__))\n",
    "VIDEO_TYPE = \"eric and asha keynote ai event\"  # See available schemas in the 'schemas' folder\n",
    "CLIP_DENSITY = \"medium\"\n",
    "TARGET_DURATION_S = 120\n",
    "PERSONALIZATION = \"exciting moments\"\n",
    "HUMAN_IN_THE_LOOP_REVIEW = True  # Set to True to enable human review\n",
    "ADD_CAPTIONS = True\n",
    "TRANSITION_TYPE = \"fade\"\n",
    "RESOLUTION = 720\n",
    "SPEED_RAMP = False\n",
    "\n",
    "# --- File Paths ---\n",
    "# These will be populated as the pipeline runs\n",
    "SCHEMA_PATH = \"\"\n",
    "ANALYSIS_RESULT_PATH = \"\"\n",
    "PREFILTERED_SEGMENTS_PATH = \"\"\n",
    "HIGHLIGHT_PLAN_PATH = \"\"\n",
    "OUTPUT_HIGHLIGHT_PATH = os.path.join(OUTPUT_DIR, \"highlight.mp4\")\n",
    "EVALUATION_REPORT_PATH = \"\"\n",
    "\n",
    "# --- Analyzer ID ---\n",
    "ANALYZER_ID = f\"auto-highlight-analyzer-{int(time.time())}\"\n",
    "\n",
    "# Basic validation\n",
    "if not SOURCE_VIDEO_PATH:\n",
    "    raise ValueError(\"SOURCE_VIDEO_PATH cannot be empty. Please specify the path to your video file.\")\n",
    "\n",
    "print(f\"Source Video: {SOURCE_VIDEO_PATH}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bbb961",
   "metadata": {},
   "source": [
    "## 1. Generate and Activate Schema\n",
    "\n",
    "First, we need to generate or activate a schema that tells the analysis service what to look for in the video. The schema is based on the `VIDEO_TYPE`, `CLIP_DENSITY`, `TARGET_DURATION_S`, and `PERSONALIZATION` settings defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dc8485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activated schema for 'eric and asha keynote ai event' -> c:\\Users\\t-kjindel\\OneDrive - Microsoft\\Desktop\\Highlights Generation Notebook\\video_analysis_schema.json\n",
      "Schema preview (first 10 lines):\n",
      "{\n",
      "  \"description\": \"Eric and Asha Keynote AI Event highlight analyzer \\u2013 segments video at key narrative moments and extracts flat metadata for each clip.\",\n",
      "  \"baseAnalyzerId\": \"prebuilt-videoAnalyzer\",\n",
      "  \"config\": {\n",
      "    \"returnDetails\": true,\n",
      "    \"segmentationMode\": \"custom\",\n",
      "    \"segmentationDefinition\": \"Segment the video at important or exciting moments of the Eric and Asha Keynote AI Event. Focus on new announcements, demos, Q&A interactions, and other high-engagement segments. Target a medium clip density, with an overall highlight reel totaling around 120 seconds. Prioritize personalization by surfacing the most exciting moments.\"\n",
      "  },\n",
      "  \"fieldSchema\": {\n",
      "    \"fields\": {\n",
      "\n",
      "Schema activated: c:\\Users\\t-kjindel\\OneDrive - Microsoft\\Desktop\\Highlights Generation Notebook\\video_analysis_schema.json\n",
      "{\n",
      "  \"description\": \"Eric and Asha Keynote AI Event highlight analyzer \\u2013 segments video at key narrative moments and extracts flat metadata for each clip.\",\n",
      "  \"baseAnalyzerId\": \"prebuilt-videoAnalyzer\",\n",
      "  \"config\": {\n",
      "    \"returnDetails\": true,\n",
      "    \"segmentationMode\": \"custom\",\n",
      "    \"segmentationDefinition\": \"Segment the video at important or exciting moments of the Eric and Asha Keynote AI Event. Focus on new announcements, demos, Q&A interactions, and other high-engagement segments. Target a medium clip density, with an overall highlight reel totaling around 120 seconds. Prioritize personalization by surfacing the most exciting moments.\"\n",
      "  },\n",
      "  \"fieldSchema\": {\n",
      "    \"fields\": {\n",
      "      \"Segments\": {\n",
      "        \"type\": \"array\",\n",
      "        \"method\": \"generate\",\n",
      "        \"items\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"SegmentId\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"generate\",\n",
      "              \"description\": \"Unique identifier for this segment.\"\n",
      "            },\n",
      "            \"StartTimeMs\": {\n",
      "              \"type\": \"integer\",\n",
      "              \"method\": \"generate\",\n",
      "              \"description\": \"Start time of this segment in milliseconds.\"\n",
      "            },\n",
      "            \"EndTimeMs\": {\n",
      "              \"type\": \"integer\",\n",
      "              \"method\": \"generate\",\n",
      "              \"description\": \"End time of this segment in milliseconds.\"\n",
      "            },\n",
      "            \"Description\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"generate\",\n",
      "              \"description\": \"Natural language description of what happens in this segment.\"\n",
      "            },\n",
      "            \"SegmentType\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"classify\",\n",
      "              \"description\": \"Overall context of this segment.\",\n",
      "              \"enum\": [\n",
      "                \"KeynoteIntro\",\n",
      "                \"SessionContent\",\n",
      "                \"Demo\",\n",
      "                \"Announcement\",\n",
      "                \"QandA\",\n",
      "                \"ClosingRemarks\",\n",
      "                \"Other\"\n",
      "              ]\n",
      "            },\n",
      "            \"Topic\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"generate\",\n",
      "              \"description\": \"Main topic or highlight of this segment.\"\n",
      "            },\n",
      "            \"Speaker\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"generate\",\n",
      "              \"description\": \"Name of the speaker(s) in this segment.\"\n",
      "            },\n",
      "            \"AudienceReaction\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"classify\",\n",
      "              \"description\": \"Estimated level of audience engagement or reaction.\",\n",
      "              \"enum\": [\n",
      "                \"Low\",\n",
      "                \"Medium\",\n",
      "                \"High\",\n",
      "                \"Very High\"\n",
      "              ]\n",
      "            },\n",
      "            \"AnnouncementType\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"classify\",\n",
      "              \"description\": \"Type of announcement made (if SegmentType=Announcement).\",\n",
      "              \"enum\": [\n",
      "                \"ProductLaunch\",\n",
      "                \"FeatureUpdate\",\n",
      "                \"ResearchHighlight\",\n",
      "                \"Collaboration\",\n",
      "                \"Other\",\n",
      "                \"None\"\n",
      "              ]\n",
      "            },\n",
      "            \"QandAQuestions\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"generate\",\n",
      "              \"description\": \"Comma-separated list of questions asked during a Q&A segment.\"\n",
      "            },\n",
      "            \"HighlightScore\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"generate\",\n",
      "              \"description\": \"AI-generated highlight-worthiness score between 0.0 and 1.0.\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import schema_manager\n",
    "\n",
    "try:\n",
    "    SCHEMA_PATH = schema_manager.activate_schema(\n",
    "        VIDEO_TYPE, \n",
    "        CLIP_DENSITY,\n",
    "        TARGET_DURATION_S,\n",
    "        PERSONALIZATION,\n",
    "        human_in_the_loop_review=HUMAN_IN_THE_LOOP_REVIEW\n",
    "    )\n",
    "    print(f\"Schema activated: {SCHEMA_PATH}\")\n",
    "    \n",
    "    # Display schema content\n",
    "    with open(SCHEMA_PATH, 'r') as f:\n",
    "        import json\n",
    "        print(json.dumps(json.load(f), indent=2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error activating schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8262d4",
   "metadata": {},
   "source": [
    "## 2. Analyze Video\n",
    "\n",
    "Now, we submit the video for analysis using the generated schema. This step can take a long time depending on the length of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c332ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Video Analysis: Satya Build Keynote (Density - 2.5, Time - 100s).mp4 ---\n",
      "Using analyzer ID: auto-highlight-analyzer-1755020560\n",
      "Attempting to authenticate using Azure CLI credentials...\n",
      "Successfully authenticated using Azure CLI.\n",
      "\n",
      "Attempting to create/update analyzer 'soccer-highlights-analyzer5314167881755020564'...\n",
      "Successfully authenticated using Azure CLI.\n",
      "\n",
      "Attempting to create/update analyzer 'soccer-highlights-analyzer5314167881755020564'...\n",
      "Successfully created or updated analyzer 'soccer-highlights-analyzer5314167881755020564'.\n",
      "\n",
      "Starting analysis for local video file: 'C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\Satya Build Keynote (Density - 2.5, Time - 100s).mp4'...\n",
      "Successfully created or updated analyzer 'soccer-highlights-analyzer5314167881755020564'.\n",
      "\n",
      "Starting analysis for local video file: 'C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\Satya Build Keynote (Density - 2.5, Time - 100s).mp4'...\n",
      "Analysis job started. You can check the results at: https://ai-aistudiotestcuwestus203841201294.openai.azure.com/contentunderstanding/analyzerResults/d8647b0b-d609-46a8-9e40-8d400bc0b6af?api-version=2025-05-01-preview\n",
      "DEBUG: Request ID for backend tracing: d8647b0b-d609-46a8-9e40-8d400bc0b6af\n",
      "\n",
      "Polling for analysis results. This may take minutes...\n",
      "Current analysis status: Running\n",
      "Analysis job started. You can check the results at: https://ai-aistudiotestcuwestus203841201294.openai.azure.com/contentunderstanding/analyzerResults/d8647b0b-d609-46a8-9e40-8d400bc0b6af?api-version=2025-05-01-preview\n",
      "DEBUG: Request ID for backend tracing: d8647b0b-d609-46a8-9e40-8d400bc0b6af\n",
      "\n",
      "Polling for analysis results. This may take minutes...\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Running\n",
      "Current analysis status: Succeeded\n",
      "Analysis completed successfully!\n",
      "\n",
      "--- Analysis Complete ---\n",
      "The final structured output has been saved to: C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\analysis_result_Satya Build Keynote (Density - 2.5, Time - 100s).json\n",
      "Video analysis complete. Results saved to: C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\analysis_result_Satya Build Keynote (Density - 2.5, Time - 100s).json\n",
      "{\n",
      "  \"id\": \"d8647b0b-d609-46a8-9e40-8d400bc0b6af\",\n",
      "  \"result\": {\n",
      "    \"analyzerId\": \"soccer-highlights-analyzer5314167881755020564\",\n",
      "    \"apiVersion\": \"2025-05-01-preview\",\n",
      "    \"contents\": [\n",
      "      {\n",
      "        \"KeyFrameTimesMs\": [\n",
      "          891,\n",
      "          1782,\n",
      "          2673,\n",
      "          3564,\n",
      "          4455,\n",
      "          6006,\n",
      "          7260,\n",
      "          7854,\n",
      "          9372,\n",
      "          10263,\n",
      "          11154,\n",
      "          12045,\n",
      "          12936,\n",
      "          14784,\n",
      "          15708,\n",
      "          16632,\n",
      "          17556,\n",
      "          18480,\n",
      "          19404,\n",
      "          20328,\n",
      "          21252,\n",
      "          22176,\n",
      "          23100,\n",
      "          24024,\n",
      "          25641,\n",
      "          26268,\n",
      "          26895,\n",
      "          28347,\n",
      "          29172,\n",
      "          29997,\n",
      "          30822,\n",
      "          31647,\n",
      "          32472,\n",
      "          34155,\n",
      "          35046,\n",
      "          35937,\n",
      "          36828,\n",
      "          37719,\n",
      "          38610,\n",
      "          39501,\n",
      "          40392,\n",
      "          41283,\n",
      "          42174,\n",
      "          43065,\n",
      "          43956,\n",
      "          44847,\n",
      "  \n",
      "...\n",
      "Current analysis status: Succeeded\n",
      "Analysis completed successfully!\n",
      "\n",
      "--- Analysis Complete ---\n",
      "The final structured output has been saved to: C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\analysis_result_Satya Build Keynote (Density - 2.5, Time - 100s).json\n",
      "Video analysis complete. Results saved to: C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\analysis_result_Satya Build Keynote (Density - 2.5, Time - 100s).json\n",
      "{\n",
      "  \"id\": \"d8647b0b-d609-46a8-9e40-8d400bc0b6af\",\n",
      "  \"result\": {\n",
      "    \"analyzerId\": \"soccer-highlights-analyzer5314167881755020564\",\n",
      "    \"apiVersion\": \"2025-05-01-preview\",\n",
      "    \"contents\": [\n",
      "      {\n",
      "        \"KeyFrameTimesMs\": [\n",
      "          891,\n",
      "          1782,\n",
      "          2673,\n",
      "          3564,\n",
      "          4455,\n",
      "          6006,\n",
      "          7260,\n",
      "          7854,\n",
      "          9372,\n",
      "          10263,\n",
      "          11154,\n",
      "          12045,\n",
      "          12936,\n",
      "          14784,\n",
      "          15708,\n",
      "          16632,\n",
      "          17556,\n",
      "          18480,\n",
      "          19404,\n",
      "          20328,\n",
      "          21252,\n",
      "          22176,\n",
      "          23100,\n",
      "          24024,\n",
      "          25641,\n",
      "          26268,\n",
      "          26895,\n",
      "          28347,\n",
      "          29172,\n",
      "          29997,\n",
      "          30822,\n",
      "          31647,\n",
      "          32472,\n",
      "          34155,\n",
      "          35046,\n",
      "          35937,\n",
      "          36828,\n",
      "          37719,\n",
      "          38610,\n",
      "          39501,\n",
      "          40392,\n",
      "          41283,\n",
      "          42174,\n",
      "          43065,\n",
      "          43956,\n",
      "          44847,\n",
      "  \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import run_video_analysis\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # This script runs the video analysis using the run_analysis function\n",
    "    success, ANALYSIS_RESULT_PATH, error = run_video_analysis.run_analysis(\n",
    "        video_path=SOURCE_VIDEO_PATH,\n",
    "        schema_path=SCHEMA_PATH,\n",
    "        analyzer_id=ANALYZER_ID\n",
    "    )\n",
    "    \n",
    "    if success:\n",
    "        print(f\"Video analysis complete. Results saved to: {ANALYSIS_RESULT_PATH}\")\n",
    "        \n",
    "        # Display a snippet of the analysis result\n",
    "        with open(ANALYSIS_RESULT_PATH, 'r') as f:\n",
    "            result_data = json.load(f)\n",
    "            print(json.dumps(result_data, indent=2, sort_keys=True)[:1000] + \"\\n...\")\n",
    "    else:\n",
    "        print(f\"Video analysis failed: {error}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during video analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5c9f5",
   "metadata": {},
   "source": [
    "## 3. Parse and Pre-filter Segments\n",
    "\n",
    "Next, we parse the raw analysis output and pre-filter the segments based on the schema's scoring. This creates a simplified list of potential highlight clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6eb1fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 1 segments -> kept 1\n",
      "Kept 100.0% of segments\n",
      "Segments parsed and pre-filtered. Results saved to: C:\\Users\\t-kjindel\\OneDrive - Microsoft\\Demo Samples\\prefiltered_segments_analysis_result_Satya Build Keynote (Density - 2.5, Time - 100s).json\n",
      "[\n",
      "  {\n",
      "    \"SegmentId\": \"1\",\n",
      "    \"SegmentType\": \"KeynoteIntro\",\n",
      "    \"Speaker\": \"Unknown\",\n",
      "    \"AudienceReaction\": \"Medium\",\n",
      "    \"AnnouncementType\": \"None\",\n",
      "    \"QandAQuestions\": \"\",\n",
      "    \"HighlightScore\": 0.75,\n",
      "    \"StartTimeMs\": 891,\n",
      "    \"EndTimeMs\": 99495,\n",
      "    \"Description\": \"The event begins with a welcome message to Microsoft Build. The stage is set with the Microsoft logo prominently displayed. The speaker enters the stage and begins the keynote, introducing the event and setting the context. The focus shifts to GitHub, indicating a discussion or announcement related to it. The speaker continues to discuss GitHub as the world's open developer platform. The segment continues with a demonstration of GitHub Copilot, showcasing its capabilities and integration. The speaker emphasizes the importance of building a secure and open ecosystem, and the segment ends with a transition to a new topic.\",\n",
      "    \"Topic\": \"Microsoft Build Keynote Introduction\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json_parser\n",
    "import json\n",
    "\n",
    "try:\n",
    "    PREFILTERED_SEGMENTS_PATH, _, _ = json_parser.process_json(\n",
    "        input_path=ANALYSIS_RESULT_PATH\n",
    "    )\n",
    "    print(f\"Segments parsed and pre-filtered. Results saved to: {PREFILTERED_SEGMENTS_PATH}\")\n",
    "\n",
    "    # Display the pre-filtered segments\n",
    "    with open(PREFILTERED_SEGMENTS_PATH, 'r') as f:\n",
    "        segments_data = json.load(f)\n",
    "        print(json.dumps(segments_data, indent=2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing segments: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5024c",
   "metadata": {},
   "source": [
    "## 4. Build Highlight Plan\n",
    "\n",
    "Using the pre-filtered segments, we now build the final highlight plan. This involves selecting the best clips to meet the `TARGET_DURATION_S` and arranging them in a compelling order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167758a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USER MESSAGE SENT TO MODEL ===\n",
      "{\n",
      "  \"video_type\": \"table tennis\",\n",
      "  \"clip_density\": 1.0,\n",
      "  \"target_duration_s\": 120,\n",
      "  \"personalization\": \"none\",\n",
      "  \"Segments\": [\n",
      "    {\n",
      "      \"SegmentId\": \"1\",\n",
      "      \"SegmentType\": \"KeynoteIntro\",\n",
      "      \"Speaker\": \"Unknown\",\n",
      "      \"AudienceReaction\": \"Medium\",\n",
      "      \"AnnouncementType\": \"None\",\n",
      "      \"QandAQuestions\": \"\",\n",
      "      \"HighlightScore\": 0.75,\n",
      "      \"StartTimeMs\": 891,\n",
      "      \"EndTimeMs\": 99495,\n",
      "      \"Description\": \"The event begins with a welcome message to Microsoft Build. The stage is set with the Microsoft logo prominently displayed. The speaker enters the stage and begins the keynote, introducing the event and setting the context. The focus shifts to GitHub, indicating a discussion or announcement related to it. The speaker continues to discuss GitHub as the world's open developer platform. The segment continues with a demonstration of GitHub Copilot, showcasing its capabilities and integration. The speaker emphasizes the importance of building a secure and open ecosystem, and the segment ends with a transition to a new topic.\",\n",
      "      \"Topic\": \"Microsoft Build Keynote Introduction\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "=== SYSTEM MESSAGE SENT TO MODEL ===\n",
      "SYSTEM\n",
      "You are a senior video-editing A.I. Your job is to create broadcast-ready highlight reels for sports or event videos.\n",
      "IMPORTANT: You must return ONLY valid JSON output matching the schema below—no extra keys, no text before or after the JSON.\n",
      "Your entire response must be parseable as valid JSON. Do not include any explanations, markdown code blocks, or text outside the JSON object.\n",
      "\n",
      "USER\n",
      "Input parameters  \n",
      "• **video_type**: “table tennis”\n",
      "• **clip_density**: 1.0 clips per minute\n",
      "• **target_duration_s**: 120 seconds (hard ceiling for total runtime)\n",
      "• **personalization**: “none”\n",
      "• **Segments** (JSON array): each object includes  \n",
      "  – `SegmentId` (string)  \n",
      "  – `StartTimeMs`, `EndTimeMs` (int)  \n",
      "  – `Description` (one sentence)  \n",
      "  – `EventType` (or `PlayEvent`) (string)  \n",
      "  – `HighlightScore` (float 0–1)  \n",
      "  – Optional extras (CommentaryExcitement, CrowdNoiseLevel, Scoreboard, etc.)\n",
      "\n",
      "Tasks  \n",
      "1. **Select** clips (chronological order) that together form the strongest three-act story for *table tennis*, aiming for approximately 1.0 clips per minute and total runtime ≤ 120 seconds. Personalization: none.  \n",
      "   ‣ For each selected clip, include its original `StartTimeMs` and `EndTimeMs` in your output.  \n",
      "   ‣ Aim for diversity of EventType; break ties via higher HighlightScore → higher CommentaryExcitement → earlier time.  \n",
      "   ‣ If fewer than needed to fill the duration, return all available and set `DidReturnFewerThanRequested = true`.  \n",
      "   ‣ When selecting, keep in mind all segments in the context of the full video, and ensure that transitions between chosen segments are smooth and not abrupt—each transition should carve in well with the previous and next segment.\n",
      "   ‣ The `SegmentId` values in your output must be exactly the same as those present in the input segments; do not rename or generate new SegmentIds.\n",
      "2. **Assign** every chosen clip to one Act: *Introduction | Climax | Resolution*. Each Act must contain ≥ 1 clip (merge acts if total clips < 3).  \n",
      "3. **Explain**—in ≤ 25 words each—why every clip is essential.  \n",
      "4. **Verify** total runtime (Σ OutMs − InMs) ≤ `target_duration_s` if provided; trim evenly from lowest-impact clips if necessary.  \n",
      "5. **Return** JSON **only**, matching this schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"SelectedClips\": [\n",
      "    {\n",
      "      \"SegmentId\": \"id1\",\n",
      "      \"StartTimeMs\": 12345,\n",
      "      \"EndTimeMs\": 23456,\n",
      "      \"Act\": \"Introduction\",\n",
      "      \"NarrativeRole\": \"Sets context …\",\n",
      "      \"WhyChosen\": \"≤25 words\"\n",
      "    }\n",
      "    /* all selected objects, chronological order */\n",
      "  ],\n",
      "  \"ActSummaries\": {\n",
      "    \"Introduction\": \"≤25 words\",\n",
      "    \"Climax\": \"≤25 words\",\n",
      "    \"Resolution\": \"≤25 words\"\n",
      "  },\n",
      "  \"DidReturnFewerThanRequested\": false\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "RESPONSE FORMAT: Return ONLY a valid JSON object. Do not include markdown formatting, code blocks, or any text outside the JSON object.\n",
      "RAW MODEL OUTPUT:\n",
      "{\n",
      "  \"SelectedClips\": [\n",
      "    {\n",
      "      \"SegmentId\": \"1\",\n",
      "      \"StartTimeMs\": 891,\n",
      "      \"EndTimeMs\": 99495,\n",
      "      \"Act\": \"Introduction\",\n",
      "      \"NarrativeRole\": \"Sets the opening context\",\n",
      "      \"WhyChosen\": \"Provides an essential welcome, preparing viewers for the action\"\n",
      "    }\n",
      "  ],\n",
      "  \"ActSummaries\": {\n",
      "    \"Introduction\": \"Initiates the event and sets the narrative stage.\",\n",
      "    \"Climax\": \"No separate act; merged for continuity.\",\n",
      "    \"Resolution\": \"No separate act; merged for continuity.\"\n",
      "  },\n",
      "  \"DidReturnFewerThanRequested\": true\n",
      "}\n",
      "✓ Final highlight plan saved to c:\\Users\\t-kjindel\\OneDrive - Microsoft\\Desktop\\Highlights Generation Notebook\\final_highlight_result.json\n",
      "Highlight plan created. Saved to: final_highlight_result.json\n",
      "{\n",
      "  \"SelectedClips\": [\n",
      "    {\n",
      "      \"SegmentId\": \"1\",\n",
      "      \"StartTimeMs\": 891,\n",
      "      \"EndTimeMs\": 99495,\n",
      "      \"Act\": \"Introduction\",\n",
      "      \"NarrativeRole\": \"Sets the opening context\",\n",
      "      \"WhyChosen\": \"Provides an essential welcome, preparing viewers for the action\"\n",
      "    }\n",
      "  ],\n",
      "  \"ActSummaries\": {\n",
      "    \"Introduction\": \"Initiates the event and sets the narrative stage.\",\n",
      "    \"Climax\": \"No separate act; merged for continuity.\",\n",
      "    \"Resolution\": \"No separate act; merged for continuity.\"\n",
      "  },\n",
      "  \"DidReturnFewerThanRequested\": true\n",
      "}\n",
      "RAW MODEL OUTPUT:\n",
      "{\n",
      "  \"SelectedClips\": [\n",
      "    {\n",
      "      \"SegmentId\": \"1\",\n",
      "      \"StartTimeMs\": 891,\n",
      "      \"EndTimeMs\": 99495,\n",
      "      \"Act\": \"Introduction\",\n",
      "      \"NarrativeRole\": \"Sets the opening context\",\n",
      "      \"WhyChosen\": \"Provides an essential welcome, preparing viewers for the action\"\n",
      "    }\n",
      "  ],\n",
      "  \"ActSummaries\": {\n",
      "    \"Introduction\": \"Initiates the event and sets the narrative stage.\",\n",
      "    \"Climax\": \"No separate act; merged for continuity.\",\n",
      "    \"Resolution\": \"No separate act; merged for continuity.\"\n",
      "  },\n",
      "  \"DidReturnFewerThanRequested\": true\n",
      "}\n",
      "✓ Final highlight plan saved to c:\\Users\\t-kjindel\\OneDrive - Microsoft\\Desktop\\Highlights Generation Notebook\\final_highlight_result.json\n",
      "Highlight plan created. Saved to: final_highlight_result.json\n",
      "{\n",
      "  \"SelectedClips\": [\n",
      "    {\n",
      "      \"SegmentId\": \"1\",\n",
      "      \"StartTimeMs\": 891,\n",
      "      \"EndTimeMs\": 99495,\n",
      "      \"Act\": \"Introduction\",\n",
      "      \"NarrativeRole\": \"Sets the opening context\",\n",
      "      \"WhyChosen\": \"Provides an essential welcome, preparing viewers for the action\"\n",
      "    }\n",
      "  ],\n",
      "  \"ActSummaries\": {\n",
      "    \"Introduction\": \"Initiates the event and sets the narrative stage.\",\n",
      "    \"Climax\": \"No separate act; merged for continuity.\",\n",
      "    \"Resolution\": \"No separate act; merged for continuity.\"\n",
      "  },\n",
      "  \"DidReturnFewerThanRequested\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import build_highlight\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Set the global variables that build_highlight.main() expects\n",
    "    build_highlight.SEGMENTS_PATH = PREFILTERED_SEGMENTS_PATH\n",
    "    build_highlight.RUNTIME_S = TARGET_DURATION_S\n",
    "    \n",
    "    # Call main function (no parameters needed)\n",
    "    build_highlight.main()\n",
    "    \n",
    "    # The output file is hardcoded to \"final_highlight_result.json\" in the same directory\n",
    "    HIGHLIGHT_PLAN_PATH = \"final_highlight_result.json\"\n",
    "    print(f\"Highlight plan created. Saved to: {HIGHLIGHT_PLAN_PATH}\")\n",
    "\n",
    "    # Display the highlight plan\n",
    "    with open(HIGHLIGHT_PLAN_PATH, 'r') as f:\n",
    "        plan_data = json.load(f)\n",
    "        print(json.dumps(plan_data, indent=2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error building highlight plan: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0d8bc",
   "metadata": {},
   "source": [
    "## 5. Stitch Video Clips\n",
    "\n",
    "With the highlight plan in place, we can now stitch the selected video clips together to create the final highlight video. This step uses `moviepy` to perform the video editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9116c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvideo_stitching\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      4\u001b[39m     video_stitching.main(\n\u001b[32m      5\u001b[39m         source_video_path=SOURCE_VIDEO_PATH,\n\u001b[32m      6\u001b[39m         highlight_plan_path=HIGHLIGHT_PLAN_PATH,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m         speed_ramp=SPEED_RAMP\n\u001b[32m     12\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\t-kjindel\\OneDrive - Microsoft\\Desktop\\Highlights Generation Notebook\\video_stitching.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmoviepy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip, TextClip, concatenate_videoclips, CompositeVideoClip, AudioFileClip, CompositeAudioClip\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "import video_stitching\n",
    "\n",
    "try:\n",
    "    video_stitching.main(\n",
    "        source_video_path=SOURCE_VIDEO_PATH,\n",
    "        highlight_plan_path=HIGHLIGHT_PLAN_PATH,\n",
    "        output_path=OUTPUT_HIGHLIGHT_PATH,\n",
    "        add_captions=ADD_CAPTIONS,\n",
    "        transition=TRANSITION_TYPE,\n",
    "        resolution=RESOLUTION,\n",
    "        speed_ramp=SPEED_RAMP\n",
    "    )\n",
    "    print(f\"Highlight video successfully created at: {OUTPUT_HIGHLIGHT_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error stitching video: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
